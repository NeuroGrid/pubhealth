{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-17T17:16:55.041915Z","iopub.execute_input":"2023-03-17T17:16:55.043096Z","iopub.status.idle":"2023-03-17T17:16:55.059585Z","shell.execute_reply.started":"2023-03-17T17:16:55.043044Z","shell.execute_reply":"2023-03-17T17:16:55.057933Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/pubhealthdataset/test.tsv\n/kaggle/input/pubhealthdataset/train.tsv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:16:55.063121Z","iopub.execute_input":"2023-03-17T17:16:55.064227Z","iopub.status.idle":"2023-03-17T17:16:55.079229Z","shell.execute_reply.started":"2023-03-17T17:16:55.064180Z","shell.execute_reply":"2023-03-17T17:16:55.077782Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'cuda:0'"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\n\nhealth_fact = load_dataset(\"health_fact\")","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:16:55.081795Z","iopub.execute_input":"2023-03-17T17:16:55.083106Z","iopub.status.idle":"2023-03-17T17:16:55.492121Z","shell.execute_reply.started":"2023-03-17T17:16:55.083058Z","shell.execute_reply":"2023-03-17T17:16:55.490940Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17c78ded29b74e2b836d66774483f7a0"}},"metadata":{}}]},{"cell_type":"code","source":"def remove_negative_label_rows(set_name):\n    df_train = health_fact[set_name].to_pandas()\n    df_train = df_train[df_train.label != -1]\n    health_fact[set_name] = Dataset.from_pandas(df_train)\n    health_fact[set_name] = health_fact[set_name].remove_columns(['__index_level_0__'])\n    \nremove_negative_label_rows('train')\nremove_negative_label_rows('validation')\nremove_negative_label_rows('test')","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:16:55.493662Z","iopub.execute_input":"2023-03-17T17:16:55.494856Z","iopub.status.idle":"2023-03-17T17:16:55.989237Z","shell.execute_reply.started":"2023-03-17T17:16:55.494809Z","shell.execute_reply":"2023-03-17T17:16:55.987984Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# health_fact['test'] = health_fact['test'].filter(lambda example: example[\"label\"] != -1 )\n# health_fact['validation'] = health_fact['validation'].filter(lambda example: example[\"label\"] != -1 )\n# health_fact['train'] = health_fact['train'].filter(lambda example: example[\"label\"] != -1 )","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:16:55.993748Z","iopub.execute_input":"2023-03-17T17:16:55.994215Z","iopub.status.idle":"2023-03-17T17:16:56.000938Z","shell.execute_reply.started":"2023-03-17T17:16:55.994167Z","shell.execute_reply":"2023-03-17T17:16:55.999402Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"health_fact","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:16:56.003470Z","iopub.execute_input":"2023-03-17T17:16:56.004701Z","iopub.status.idle":"2023-03-17T17:16:56.013793Z","shell.execute_reply.started":"2023-03-17T17:16:56.004622Z","shell.execute_reply":"2023-03-17T17:16:56.012396Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['claim_id', 'claim', 'date_published', 'explanation', 'fact_checkers', 'main_text', 'sources', 'label', 'subjects'],\n        num_rows: 9804\n    })\n    test: Dataset({\n        features: ['claim_id', 'claim', 'date_published', 'explanation', 'fact_checkers', 'main_text', 'sources', 'label', 'subjects'],\n        num_rows: 1233\n    })\n    validation: Dataset({\n        features: ['claim_id', 'claim', 'date_published', 'explanation', 'fact_checkers', 'main_text', 'sources', 'label', 'subjects'],\n        num_rows: 1214\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\ntokenized_explanations = tokenizer(health_fact[\"train\"][\"explanation\"], max_length=512, truncation=True, padding=True, return_tensors=\"pt\") #.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:16:56.016167Z","iopub.execute_input":"2023-03-17T17:16:56.017182Z","iopub.status.idle":"2023-03-17T17:17:02.046053Z","shell.execute_reply.started":"2023-03-17T17:16:56.017137Z","shell.execute_reply":"2023-03-17T17:17:02.044919Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\nloading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at None\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(example[\"explanation\"], max_length=512, truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:17:02.048542Z","iopub.execute_input":"2023-03-17T17:17:02.049222Z","iopub.status.idle":"2023-03-17T17:17:02.055311Z","shell.execute_reply.started":"2023-03-17T17:17:02.049179Z","shell.execute_reply":"2023-03-17T17:17:02.054229Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = health_fact.map(tokenize_function, batched=True)\ntokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:17:02.056768Z","iopub.execute_input":"2023-03-17T17:17:02.057836Z","iopub.status.idle":"2023-03-17T17:17:10.672166Z","shell.execute_reply.started":"2023-03-17T17:17:02.057794Z","shell.execute_reply":"2023-03-17T17:17:10.670850Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58f11a139bf84f84b9e5ddb968da09c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36660bed171a4cc99993e724f5103548"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24dca7808bfb48f281907f0fc4887d40"}},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['claim_id', 'claim', 'date_published', 'explanation', 'fact_checkers', 'main_text', 'sources', 'label', 'subjects', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9804\n    })\n    test: Dataset({\n        features: ['claim_id', 'claim', 'date_published', 'explanation', 'fact_checkers', 'main_text', 'sources', 'label', 'subjects', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1233\n    })\n    validation: Dataset({\n        features: ['claim_id', 'claim', 'date_published', 'explanation', 'fact_checkers', 'main_text', 'sources', 'label', 'subjects', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1214\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:17:10.674378Z","iopub.execute_input":"2023-03-17T17:17:10.675206Z","iopub.status.idle":"2023-03-17T17:17:10.681836Z","shell.execute_reply.started":"2023-03-17T17:17:10.675160Z","shell.execute_reply":"2023-03-17T17:17:10.680328Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:17:10.683851Z","iopub.execute_input":"2023-03-17T17:17:10.684673Z","iopub.status.idle":"2023-03-17T17:17:10.705035Z","shell.execute_reply.started":"2023-03-17T17:17:10.684626Z","shell.execute_reply":"2023-03-17T17:17:10.703711Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=4) #.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:17:10.706833Z","iopub.execute_input":"2023-03-17T17:17:10.707615Z","iopub.status.idle":"2023-03-17T17:17:12.771059Z","shell.execute_reply.started":"2023-03-17T17:17:10.707568Z","shell.execute_reply":"2023-03-17T17:17:12.769957Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\",\n    \"3\": \"LABEL_3\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2,\n    \"LABEL_3\": 3\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:17:12.772710Z","iopub.execute_input":"2023-03-17T17:17:12.773191Z","iopub.status.idle":"2023-03-17T17:17:24.578899Z","shell.execute_reply.started":"2023-03-17T17:17:12.773150Z","shell.execute_reply":"2023-03-17T17:17:24.577624Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.7/site-packages (0.4.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.21.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.3.5)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.12.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.28.2)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2023.1.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.64.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.11.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from evaluate) (23.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (5.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.11.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2022.7.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\n# metric = evaluate.load(\"f1\", average=\"weighted\") # not working? https://discuss.huggingface.co/t/combining-metrics-for-multiclass-predictions-evaluations/21792/10\nf1_metric = evaluate.load(\"f1\")\n\ndef compute_metrics (eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis = -1)\n    \n    results = {}\n    results.update(f1_metric.compute(predictions=preds, references = labels, average=\"micro\"))\n    return results\n\n# def compute_metrics(eval_preds):\n\n#     logits, labels = eval_preds\n#     predictions = np.argmax(logits, axis=-1)\n#     return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:35:27.742888Z","iopub.execute_input":"2023-03-17T17:35:27.743904Z","iopub.status.idle":"2023-03-17T17:35:28.353627Z","shell.execute_reply.started":"2023-03-17T17:35:27.743866Z","shell.execute_reply":"2023-03-17T17:35:28.352117Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:35:35.722373Z","iopub.execute_input":"2023-03-17T17:35:35.723089Z","iopub.status.idle":"2023-03-17T17:35:35.740183Z","shell.execute_reply.started":"2023-03-17T17:35:35.723053Z","shell.execute_reply":"2023-03-17T17:35:35.738942Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:35:37.782404Z","iopub.execute_input":"2023-03-17T17:35:37.783075Z","iopub.status.idle":"2023-03-17T17:36:01.585011Z","shell.execute_reply.started":"2023-03-17T17:35:37.783038Z","shell.execute_reply":"2023-03-17T17:36:01.579886Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: claim, explanation, claim_id, sources, subjects, fact_checkers, main_text, date_published. If claim, explanation, claim_id, sources, subjects, fact_checkers, main_text, date_published are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 1214\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='304' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [152/152 10:12]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.7118145823478699,\n 'eval_f1': 0.7224052718286654,\n 'eval_runtime': 23.7524,\n 'eval_samples_per_second': 51.111,\n 'eval_steps_per_second': 6.399}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:36:10.001811Z","iopub.execute_input":"2023-03-17T17:36:10.002235Z","iopub.status.idle":"2023-03-17T18:05:13.533458Z","shell.execute_reply.started":"2023-03-17T17:36:10.002198Z","shell.execute_reply":"2023-03-17T18:05:13.532498Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: claim, explanation, claim_id, sources, subjects, fact_checkers, main_text, date_published. If claim, explanation, claim_id, sources, subjects, fact_checkers, main_text, date_published are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 9804\n  Num Epochs = 3\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 3678\n  Number of trainable parameters = 109485316\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3678' max='3678' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3678/3678 29:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.612200</td>\n      <td>0.697932</td>\n      <td>0.751236</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.402200</td>\n      <td>0.915149</td>\n      <td>0.750412</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.233500</td>\n      <td>1.290851</td>\n      <td>0.741351</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to test-trainer/checkpoint-500\nConfiguration saved in test-trainer/checkpoint-500/config.json\nModel weights saved in test-trainer/checkpoint-500/pytorch_model.bin\ntokenizer config file saved in test-trainer/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in test-trainer/checkpoint-500/special_tokens_map.json\nSaving model checkpoint to test-trainer/checkpoint-1000\nConfiguration saved in test-trainer/checkpoint-1000/config.json\nModel weights saved in test-trainer/checkpoint-1000/pytorch_model.bin\ntokenizer config file saved in test-trainer/checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in test-trainer/checkpoint-1000/special_tokens_map.json\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: claim, explanation, claim_id, sources, subjects, fact_checkers, main_text, date_published. If claim, explanation, claim_id, sources, subjects, fact_checkers, main_text, date_published are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 1214\n  Batch size = 8\nSaving model checkpoint to test-trainer/checkpoint-1500\nConfiguration saved in test-trainer/checkpoint-1500/config.json\nModel weights saved in test-trainer/checkpoint-1500/pytorch_model.bin\ntokenizer config file saved in test-trainer/checkpoint-1500/tokenizer_config.json\nSpecial tokens file saved in test-trainer/checkpoint-1500/special_tokens_map.json\nSaving model checkpoint to test-trainer/checkpoint-2000\nConfiguration saved in test-trainer/checkpoint-2000/config.json\nModel weights saved in test-trainer/checkpoint-2000/pytorch_model.bin\ntokenizer config file saved in test-trainer/checkpoint-2000/tokenizer_config.json\nSpecial tokens file saved in test-trainer/checkpoint-2000/special_tokens_map.json\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: claim, explanation, claim_id, sources, subjects, fact_checkers, main_text, date_published. If claim, explanation, claim_id, sources, subjects, fact_checkers, main_text, date_published are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 1214\n  Batch size = 8\nSaving model checkpoint to test-trainer/checkpoint-2500\nConfiguration saved in test-trainer/checkpoint-2500/config.json\nModel weights saved in test-trainer/checkpoint-2500/pytorch_model.bin\ntokenizer config file saved in test-trainer/checkpoint-2500/tokenizer_config.json\nSpecial tokens file saved in test-trainer/checkpoint-2500/special_tokens_map.json\nSaving model checkpoint to test-trainer/checkpoint-3000\nConfiguration saved in test-trainer/checkpoint-3000/config.json\nModel weights saved in test-trainer/checkpoint-3000/pytorch_model.bin\ntokenizer config file saved in test-trainer/checkpoint-3000/tokenizer_config.json\nSpecial tokens file saved in test-trainer/checkpoint-3000/special_tokens_map.json\nSaving model checkpoint to test-trainer/checkpoint-3500\nConfiguration saved in test-trainer/checkpoint-3500/config.json\nModel weights saved in test-trainer/checkpoint-3500/pytorch_model.bin\ntokenizer config file saved in test-trainer/checkpoint-3500/tokenizer_config.json\nSpecial tokens file saved in test-trainer/checkpoint-3500/special_tokens_map.json\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: claim, explanation, claim_id, sources, subjects, fact_checkers, main_text, date_published. If claim, explanation, claim_id, sources, subjects, fact_checkers, main_text, date_published are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 1214\n  Batch size = 8\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3678, training_loss=0.42338477586390466, metrics={'train_runtime': 1743.4626, 'train_samples_per_second': 16.87, 'train_steps_per_second': 2.11, 'total_flos': 7738761324183552.0, 'train_loss': 0.42338477586390466, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('test-trainer-with-metrics')","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:27:53.274572Z","iopub.status.idle":"2023-03-17T17:27:53.275615Z","shell.execute_reply.started":"2023-03-17T17:27:53.275290Z","shell.execute_reply":"2023-03-17T17:27:53.275322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:27:53.278571Z","iopub.status.idle":"2023-03-17T17:27:53.279362Z","shell.execute_reply.started":"2023-03-17T17:27:53.279078Z","shell.execute_reply":"2023-03-17T17:27:53.279112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nf1_metric = evaluate.load(\"f1\")\nresults = f1_metric.compute(predictions=[0, 1], references=[0, 1])\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:27:53.281133Z","iopub.status.idle":"2023-03-17T17:27:53.283359Z","shell.execute_reply.started":"2023-03-17T17:27:53.283069Z","shell.execute_reply":"2023-03-17T17:27:53.283100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets[\"validation\"][0:1]\nNone","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:27:53.284923Z","iopub.status.idle":"2023-03-17T17:27:53.285962Z","shell.execute_reply.started":"2023-03-17T17:27:53.285662Z","shell.execute_reply":"2023-03-17T17:27:53.285693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probe = {\n    'explanation': ['Fellow Twitter users suggested @FierceFemtivist indicated she was from Louisville, Kentucky, prior to deleting her account. We were unable to locate any news reports of unusual infant deaths on 8 November 2015 in that area, nor were we able to confirm that the purported incident took place in Louisville (or at all):'],\n    'labels': [3]\n}","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:27:53.287978Z","iopub.status.idle":"2023-03-17T17:27:53.289131Z","shell.execute_reply.started":"2023-03-17T17:27:53.288824Z","shell.execute_reply":"2023-03-17T17:27:53.288855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = trainer.predict(tokenized_datasets[\"validation\"])\nprint(predictions.predictions.shape, predictions.label_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:27:53.291483Z","iopub.status.idle":"2023-03-17T17:27:53.292795Z","shell.execute_reply.started":"2023-03-17T17:27:53.292515Z","shell.execute_reply":"2023-03-17T17:27:53.292546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2023-03-17T17:27:53.294245Z","iopub.status.idle":"2023-03-17T17:27:53.295159Z","shell.execute_reply.started":"2023-03-17T17:27:53.294897Z","shell.execute_reply":"2023-03-17T17:27:53.294925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}